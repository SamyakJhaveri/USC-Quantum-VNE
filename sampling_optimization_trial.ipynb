{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sebremforqubo(Qfull, beta, Niterations, EmbeddingFlag, step):\n",
    "    # Qfull - QUBO matrix \n",
    "    # beta - a temperature parameter \n",
    "    # Niterations - the number of iterations to run the algorithm \n",
    "    # EmbeddingFlag - a flag to indicate whether to perform an embedding step \n",
    "    # Step - a step size\n",
    "\n",
    "    \n",
    "    MAX_N_SOLUTIONS = 40000 # the maximum number of solutions to return\n",
    "    Nqubits = 512 # number of qubits to use\n",
    "    Nvariables = Qfull.shape[0]\n",
    "    params = {'num_reads': 10000, 'auto_scale': False} # the number of reads per run\n",
    "    absJmax = 1\n",
    "    abshmax = 2\n",
    "    SampleScaleFactor = 0.99\n",
    "\n",
    "    RelativeEntropy = np.zeros(Niterations)\n",
    "    BestObjective = np.zeros(Niterations)\n",
    "\n",
    "    # Obtain Adjacency matrix and list of qubits used\n",
    "    \n",
    "    # affiliate connection flag\n",
    "    aff = 0\n",
    "    # Choose a connection depending on the time of day\n",
    "    import datetime\n",
    "    now = datetime.datetime.now()\n",
    "    if now.hour in [4, 9, 14, 19]:\n",
    "        # Creates a remote SAPI connection handle to the affiliate server\n",
    "        conn = sapiRemoteConnection('https://206.117.25.108/sapi/','92cc484c78372afc3810749cf106e95c76540571')\n",
    "        aff = 1\n",
    "    else:\n",
    "        # Creates a remote SAPI connection handle to the ISI server\n",
    "        conn = sapiRemoteConnection('https://206.117.25.107/sapi/','d6d46de897c148729afb655909aff78d0eb125ea')\n",
    "\n",
    "    # Create a SAPI solver handle\n",
    "    if aff==1:\n",
    "        solver = sapiSolver(conn,'V6-LP') # Hardware Low Priority (affiliate)\n",
    "    else:\n",
    "        solver = sapiSolver(conn,'V6-MP') # Hardware Medium Priority\n",
    "\n",
    "    AdjacencyMatrix = getHardwareAdjacency(solver)\n",
    "    QubitsUsed = GenerateQubitsUsed(AdjacencyMatrix)\n",
    "\n",
    "    # Shift QubitsUsed to use a different part of the chip\n",
    "    # QubitsUsed = QubitsUsed - 128; # Shifts everything 2 cells up\n",
    "    \n",
    "    # the rest of the algorithm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QubitMapping, couplers, VariableInteraction, h_chimera, J_chimera, hfull, Jfull = InitialEmbedding(Qfull, EmbeddingFlag, AdjacencyMatrix, QubitsUsed)\n",
    "\n",
    "EmbeddingData = {}\n",
    "EmbeddingData['Qmap'] = QubitMapping\n",
    "EmbeddingData['couplers'] = couplers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is Happening here ?\n",
    "\n",
    "IsingEnergy = lambda S: (S.T@Jfull@S + S.T@hfull)\n",
    "\n",
    "# OR this one ðŸ‘‡ðŸ»\n",
    "IsingEnergy = partial(np.dot, np.dot(Jfull, np.transpose(S)) + np.dot(np.transpose(S), hfull))\n",
    "\n",
    "def IsingEnergy(S):\n",
    "    return np.dot(np.dot(Jfull, np.transpose(S)) + np.dot(np.transpose(S), hfull))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iter in range(Niterations):\n",
    "\n",
    "    # Solve the Ising model with quantum processor\n",
    "    answer = IsingConnectSolve(SampleScaleFactor*h_chimera, SampleScaleFactor*J_chimera, params)\n",
    "\n",
    "    # NumberOfSamples = size(answer.solutions,2);\n",
    "    NumberOfSamples = answer.solutions.shape[1]\n",
    "\n",
    "    # Extract a distribution from the samples\n",
    "    SpinSolutions, ProbabilityOfSamples, EnergiesOfSamples[iter] = ExtractDistribution(answer, QubitMapping)\n",
    "\n",
    "    # Compute objective function on samples\n",
    "    Gvec = GvecComputation(SpinSolutions, IsingEnergy)  # Compute the values of the normalized original function on the samples\n",
    "    G[iter] = Gvec\n",
    "\n",
    "    # Extract best solutions\n",
    "    BestObjective[iter], BestSolutions[iter] = FindBestSolution(SpinSolutions, Gvec, Qfull)\n",
    "\n",
    "    # Compute the relative entropy\n",
    "    RelativeEntropy[iter] = -ProbabilityOfSamples * np.log(ProbabilityOfSamples) + beta * (Gvec * ProbabilityOfSamples)\n",
    "\n",
    "    # Compute the gradient of the relative entropy\n",
    "    GradRE_h, GradRE_J = REGradient(SpinSolutions, ProbabilityOfSamples, Gvec, beta, VariableInteraction)\n",
    "    Grad[iter, :] = [GradRE_h, GradRE_J]\n",
    "    if iter > 1:\n",
    "        GradInnerProduct = Grad[iter, :] * Grad[iter - 1, :] / (np.linalg.norm(Grad[iter - 1, :]) * np.linalg.norm(Grad[iter, :]))\n",
    "    else:\n",
    "        GradInnerProduct = 0\n",
    "\n",
    "    # Update Ising model\n",
    "    if GradInnerProduct < -0.1:\n",
    "        Step = max(0.005, Step / 3)\n",
    "    elif GradInnerProduct > 0.5:\n",
    "        Step = min(0.1, Step * 3)\n",
    "\n",
    "    h_chimera, J_chimera = UpdateIsingModel(h_chimera, J_chimera, GradRE_h, GradRE_J, Step, QubitMapping, couplers, BestObjective, BestSolutions, iter)\n",
    "\n",
    "    h[iter] = h_chimera\n",
    "    J[iter] = J_chimera\n",
    "    num_samples[iter] = NumberOfSamples\n",
    "    step[iter] = Step\n",
    "\n",
    "    # Start printing information\n",
    "    DisplayInformation(RelativeEntropy, iter, BestObjective, BestSolutions, beta, Niterations, GradInnerProduct, NumberOfSamples)\n",
    "\n",
    "    # Save data\n",
    "    np.savez(\"SEBREMdata\", BestObjective=BestObjective, BestSolutions=BestSolutions, G=G, EnergiesOfSamples=EnergiesOfSamples, Grad=Grad, RelativeEntropy=RelativeEntropy, h=h, J=J)\n",
    "\n",
    "    EmbeddingData['h'] = h\n",
    "    EmbeddingData['J'] = J\n",
    "    EmbeddingData['num_samples'] = num_samples\n",
    "    EmbeddingData['step'] = step\n",
    "\n",
    "# Extract best solution\n",
    "bestindex = np.argmin(BestObjective)\n",
    "BestObjectiveFound = BestObjective[bestindex]\n",
    "BestSolutionFound = BestSolutions[bestindex][:, 0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import linprog\n",
    "from scipy.sparse import csgraph\n",
    "\n",
    "def InitialEmbedding(Qfull, EmbeddingFlag, AdjacencyMatrix, QubitsUsed):\n",
    "    # Parameters\n",
    "    Nqubits = 512\n",
    "    absJmax = 1\n",
    "    abshmax = 2\n",
    "\n",
    "    StartingQubit = 217  # First qubit of one of the central cells\n",
    "\n",
    "    # Convert Qfull to upper triangular\n",
    "    Qfull = np.triu(Qfull) + np.triu(Qfull.T, 1)\n",
    "\n",
    "    # Convert to Ising model to allow proper normalization\n",
    "    hfull, Jfull = quboToIsing(Qfull)  # Now Jfull is also upper triangular\n",
    "\n",
    "    # Normalize\n",
    "    NormFactor = max((1 / abshmax) * np.max(np.abs(hfull)), (1 / absJmax) * np.max(np.abs(Jfull)))\n",
    "    hfull = hfull / NormFactor\n",
    "    Jfull = Jfull / NormFactor\n",
    "\n",
    "    # Construct initial embedding\n",
    "    if EmbeddingFlag == 1:  # Apply the greedy embedding algorithm to find a starting embedding\n",
    "        QubitMapping, AdjMat = GreedyEmbedding(Jfull, AdjacencyMatrix, StartingQubit)\n",
    "    elif EmbeddingFlag == 2:  # Apply stochastic version of greedy embedding\n",
    "        QubitMapping, AdjMat = StochasticGreedyEmbedding(Jfull, AdjacencyMatrix, StartingQubit)\n",
    "    else:\n",
    "        QubitMapping, AdjMat = RandomizedDirectEmbedding(Jfull, AdjacencyMatrix, QubitsUsed)\n",
    "\n",
    "    # Embedded J: AdjMat is only an adjacency matrix\n",
    "    # J_chimera should be upper triangular (because Jfull is)\n",
    "    J_chimera = np.zeros((Nqubits, Nqubits))\n",
    "    h_chimera = np.zeros(Nqubits)\n",
    "\n",
    "    J_chimera[QubitMapping[:, 1], QubitMapping[:, 1]] = Jfull * AdjMat\n",
    "    J_chimera = np.triu(J_chimera)  # Keep J_chimera upper triangular\n",
    "\n",
    "    h_chimera[QubitMapping[:, 1]] = hfull  # Assign local fields\n",
    "\n",
    "    # Check if there is a zero row/column in J_chimera for which\n",
    "    # h_chimera is also zero, and add a very small local field if that is the\n",
    "    # case\n",
    "    ZeroDetect = np.sum(np.abs(np.column_stack((h_chimera[QubitMapping[:, 1]], np.sum(Jfull * AdjMat + (Jfull * AdjMat).T, axis=1)))), axis=1)\n",
    "    if np.any(ZeroDetect == 0):\n",
    "        h_chimera[QubitMapping[ZeroDetect == 0, 1]] = 0.001\n",
    "\n",
    "    # Inverse QubitMapping\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtractDistribution(answer, QubitMapping):\n",
    "    SpinSolutions = answer[\"solutions\"][QubitMapping[:, 2], :]\n",
    "    ProbabilityOfSamples = answer[\"num_occurrences\"] / sum(answer[\"num_occurrences\"])\n",
    "    EnergiesOfSamples = answer[\"energies\"]\n",
    "    return SpinSolutions, ProbabilityOfSamples, EnergiesOfSamples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GreedyEmbedding(J, AdjacencyMatrix, StartingQubit):\n",
    "    J = J - np.diag(np.diag(J))\n",
    "\n",
    "    Nvars = J.shape[0]\n",
    "    Nqubits = 512\n",
    "    Qubit = StartingQubit\n",
    "\n",
    "    MissingQubits = np.where((np.sum(AdjacencyMatrix, axis=1)) == 0)[0]\n",
    "    for i in range(len(MissingQubits)):\n",
    "        AdjacencyMatrix[MissingQubits[i], :] = 0*AdjacencyMatrix[MissingQubits[i], :]\n",
    "        AdjacencyMatrix[:, MissingQubits[i]] = 0*AdjacencyMatrix[:, MissingQubits[i]]\n",
    "\n",
    "    StrongCouplingIndex = np.argmax(np.sum(np.abs(J)))\n",
    "\n",
    "    VariablesLeft = np.arange(Nvars)\n",
    "    VariablesAssigned = []\n",
    "\n",
    "    QubitsAssigned = []\n",
    "    QubitsLeft = np.arange(Nqubits)\n",
    "    QubitsLeft = np.delete(QubitsLeft, MissingQubits)\n",
    "\n",
    "    VariablesAssigned.append(StrongCouplingIndex)\n",
    "    VariablesLeft = np.delete(VariablesLeft, StrongCouplingIndex)\n",
    "    J[:, StrongCouplingIndex] = np.zeros(Nvars)\n",
    "\n",
    "    QubitsAssigned.append(Qubit)\n",
    "\n",
    "    QubitNeighbors = np.where(AdjacencyMatrix[Qubit, :] != 0)[0]\n",
    "\n",
    "    for n in range(2, Nvars):\n",
    "        for i in range(len(VariablesLeft)):\n",
    "            for j in range(len(QubitNeighbors)):\n",
    "                Coupling = 0\n",
    "                for k in range(len(VariablesAssigned)):\n",
    "                    Coupling += abs(J[VariablesAssigned[k], VariablesLeft[i]])*AdjacencyMatrix[QubitNeighbors[j], QubitsAssigned[k]]\n",
    "                CouplingStrength[i, j] = Coupling\n",
    "\n",
    "        MaxCouplingStrength = np.amax(CouplingStrength)\n",
    "        PossibleNewQubitIndices = np.where(np.amax(CouplingStrength, axis=1) == MaxCouplingStrength)[0]\n",
    "        for nqi in range(len(PossibleNewQubitIndices)):\n",
    "            DistanceToLastAssignedQubit[nqi] = abs(QubitsAssigned[-1]-QubitNeighbors[PossibleNewQubitIndices[nqi]])\n",
    "        MinIndex = np.argmin(DistanceToLastAssignedQubit)\n",
    "        NewQubit = QubitNeighbors[PossibleNewQubitIndices[MinIndex]]\n",
    "\n",
    "        NewVarIndex = np.argmax(CouplingStrength[:, NewQubitIndex])\n",
    "        NewVar = VariablesLeft[NewVarIndex]\n",
    "\n",
    "        VariablesAssigned.append(NewVar)\n",
    "        VariablesLeft = np.delete(VariablesLeft, np.where(VariablesLeft == NewVar)[0])\n",
    "\n",
    "        QubitsAssigned.append(NewQubit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GvecComputation(SpinSolutions, G):\n",
    "    Gvec = np.apply_along_axis(G, 1, SpinSolutions)\n",
    "    return Gvec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HammingDistance(String1, String2):\n",
    "distance = sum(np.mod(String1 + String2, 2))\n",
    "return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def REGradient(SpinSolutions,ProbabilityOfSamples,Gvec,beta,VariableInteraction):\n",
    "    #RECOMPUTATION COmputes the relative entropy and its gradient\n",
    "    #   It takes the structure answer as input and computes the relative\n",
    "    #   entropy between the input QUBO and the embedded one. Note that internally \n",
    "    #   the code works in the Ising framework, so solutions are strings of\n",
    "    #   {+1,-1}. \n",
    "\n",
    "    # Notes:\n",
    "    # -When yo urun the deivce 100 times and you want to know the \n",
    "\n",
    "    sampleset[\"info\"]\n",
    "\n",
    "\n",
    "    \n",
    "    Nvariables = SpinSolutions.shape[0]\n",
    "\n",
    "    # Fast gradient computation\n",
    "\n",
    "    Corr1 = SpinSolutions@ProbabilityOfSamples.T # Vector of mean values of variables\n",
    "\n",
    "    Corr2 = SpinSolutions@np.diag(ProbabilityOfSamples)@SpinSolutions.T\n",
    "    VecCorr2 = Corr2.reshape(-1) # Vectorized two-variable correlation matrix\n",
    "\n",
    "    Corr2coupler = VecCorr2[VariableInteraction[:,0] +(VariableInteraction[:,1] -1)*Nvariables] # Two variable correlations associated with just the couplers\n",
    "\n",
    "\n",
    "    Hvec = ProbabilityOfSamples*(np.log2(ProbabilityOfSamples) + beta*Gvec)\n",
    "\n",
    "    ProdVec = SpinSolutions[VariableInteraction[:,0],:]*SpinSolutions[VariableInteraction[:,1],:]\n",
    "\n",
    "    AverageLog = (np.log2(ProbabilityOfSamples) + beta*Gvec)*ProbabilityOfSamples\n",
    "\n",
    "\n",
    "    GradRE_h = -beta*(SpinSolutions@Hvec.T - Corr1*AverageLog).T\n",
    "    GradRE_J = -beta*(ProdVec@Hvec.T - Corr2coupler*AverageLog).T\n",
    "\n",
    "    return GradRE_h,GradRE_J\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UpdateIsingModel(h_chimera, J_chimera, GradRE_h, GradRE_J, Step, QubitMapping, couplers, BestObjective, BestSolutions, iter):\n",
    "    absJmax = 1\n",
    "    abshmax = 2\n",
    "\n",
    "    Nvariables = QubitMapping.shape[0]\n",
    "    MaxCouplers = couplers.shape[0]\n",
    "    Nqubits = len(h_chimera)\n",
    "\n",
    "    # First, we need to map the free parameters in h_chimera and J_chimera into\n",
    "    # a vector of parameters in order to facilitate some of the calculations\n",
    "\n",
    "    Parameters = np.zeros(Nvariables + MaxCouplers)\n",
    "    Parameters[:Nvariables] = h_chimera[QubitMapping[:,1]-1]\n",
    "    Parameters[Nvariables:] = J_chimera[(couplers[:,1]-1)*Nqubits + couplers[:,0]-1]\n",
    "\n",
    "    GradParameters = np.concatenate((GradRE_h, GradRE_J))\n",
    "\n",
    "    ParametersMin = np.concatenate((-abshmax*np.ones(Nvariables), -absJmax*np.ones(MaxCouplers)))\n",
    "    ParametersMax = np.concatenate((abshmax*np.ones(Nvariables), absJmax*np.ones(MaxCouplers)))\n",
    "\n",
    "    # Find vector of max allowed update steps for all parameters\n",
    "\n",
    "    I_positive = np.where(GradParameters > 0)\n",
    "    alpha = np.zeros(Nvariables + MaxCouplers)\n",
    "    alpha[I_positive] = (Parameters[I_positive] - ParametersMin[I_positive])/GradParameters[I_positive]\n",
    "\n",
    "    I_negative = np.where(GradParameters < 0)\n",
    "    alpha[I_negative] = (Parameters[I_negative] - ParametersMax[I_negative])/GradParameters[I_negative]\n",
    "\n",
    "    I_zero = np.where(GradParameters == 0)\n",
    "    alpha[I_zero] = 10**10\n",
    "\n",
    "    # Find the minimum value of allowed update steps\n",
    "\n",
    "    alpha_min = np.min(alpha)\n",
    "\n",
    "    # Update the parameters, using an update mask to prevent moving outside the\n",
    "    # constraint box parameters that are already at the boundary\n",
    "\n",
    "    UpdatedParameters = Parameters - min(alpha_min,Step)*(GradParameters*(1 - (np.abs(np.abs(Parameters) - ParametersMax) < 10**(-8)) * (np.sign(Parameters*GradParameters) < 0)))\n",
    "\n",
    "    # Now we need to map back the update parameters into the vector h_chimera\n",
    "    # and the matrix J_chimera\n",
    "\n",
    "    h_chimera[QubitMapping[:,1]-1] = UpdatedParameters[:Nvariables]\n",
    "    J_chimera[(couplers[:,1]-1)*Nqubits + couplers[:,0]-1] = UpdatedParameters[Nvariables:]\n",
    "\n",
    "    MIXFACTOR = 0.05  # If the new optimum is better, add an Ising model whose ground state corresponds to it.\n",
    "\n",
    "    if iter > 1 and BestObjective[iter] <= np.min(BestObject\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ChimeraParametersFromBinarySolution(BinarySolutions, QubitMapping, couplers):\n",
    "    Nqubits = QubitMapping.shape[0]\n",
    "\n",
    "    FullSolution = np.zeros(512)\n",
    "    h = np.zeros(512)\n",
    "    J = np.zeros((512, 512))\n",
    "\n",
    "    NumberOfBestSolutions = BinarySolutions.shape[1]\n",
    "\n",
    "    for soln in range(NumberOfBestSolutions):\n",
    "        FullSolution[QubitMapping[:,1]] = 2*BinarySolutions[:,soln]-1\n",
    "\n",
    "        h = h -(0.2/NumberOfBestSolutions)*FullSolution # Check sign\n",
    "\n",
    "        for i in range(couplers.shape[0]):\n",
    "            J[couplers[i,0],couplers[i,1]] = J[couplers[i,0],couplers[i,1]] - (1/NumberOfBestSolutions)*FullSolution[couplers[i,0]]*FullSolution[couplers[i,1]]\n",
    "    return h,J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FindBestSolution(SpinSolutions, Gvec, Qfull):\n",
    "    # Order Gvec\n",
    "    OrderedGvec = Gvec[np.argsort(Gvec[:,0])]\n",
    "\n",
    "    # Order SpinSolutions\n",
    "    sortindices = np.argsort(Gvec[:,0])\n",
    "    OrderedSpinSolutions = SpinSolutions[:,sortindices]\n",
    "\n",
    "    # Find how many solutions attain the lowest objective\n",
    "    NumberOfGroundStates = len(np.where(OrderedGvec[:,0] == OrderedGvec[0,0])[0])\n",
    "\n",
    "    # Extract best solutions\n",
    "    BestSolution = (OrderedSpinSolutions[:,0:NumberOfGroundStates] + 1)/2 # Gives a binary string\n",
    "    BestObjective = np.dot(np.dot(BestSolution[:,0].T, Qfull), BestSolution[:,0])\n",
    "\n",
    "    return BestObjective, BestSolution\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DisplayInformation(RelativeEntropy, iter, BestObjective, BestSolutions, beta, Niterations, GradInnerProduct, NumberOfSamples):\n",
    "    def HammingDistance(str1, str2):\n",
    "        diffs = 0\n",
    "        for ch1, ch2 in zip(str1, str2):\n",
    "            if ch1 != ch2:\n",
    "                diffs += 1\n",
    "        return diffs\n",
    "\n",
    "    if iter == 1:\n",
    "        print(' ')\n",
    "        print('SEQUENTIAL EMBEDDING BY RELATIVE ENTROPY MINIMIZATION ')\n",
    "        print(' ')\n",
    "        print('Parameters: beta = {}, Number of Iterations = {}'.format(beta, Niterations))\n",
    "        print(' ')\n",
    "        print('Iter \\t RE \\t Best objective \\t Hamming Distance \\t Gradient angle \\t Samples')\n",
    "        print('{} \\t {} \\t {}'.format(iter, RelativeEntropy[iter], BestObjective[iter]))\n",
    "        \n",
    "    else:\n",
    "        Hdistance = np.zeros((BestSolutions[iter].shape[1], BestSolutions[iter-1].shape[1]))\n",
    "        for i in range(BestSolutions[iter].shape[1]):\n",
    "            for j in range(BestSolutions[iter-1].shape[1]):\n",
    "                Hdistance[i,j] = HammingDistance(BestSolutions[iter-1][:,j], BestSolutions[iter][:,i])\n",
    "        hammingdistance = np.min(np.min(Hdistance))\n",
    "        print('{} \\t {} \\t {} \\t {} \\t {} \\t {}'.format(iter, RelativeEntropy[iter], BestObjective[iter], hammingdistance, GradInnerProduct, NumberOfSamples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomizedDirectEmbedding(J, AdjacencyMatrix, QubitsUsed):\n",
    "    J = J - np.diag(np.diag(J))\n",
    "\n",
    "    Nvariables = J.shape[0]\n",
    "    Nqubits = 512\n",
    "\n",
    "    MissingQubits = np.where(np.sum(AdjacencyMatrix, axis=0) == 0)[0] # Missing qubits in processor\n",
    "\n",
    "    #Remove Missing qubits from AdjacencyMatrix (in case they're still there)\n",
    "    for i in range(len(MissingQubits)):\n",
    "        AdjacencyMatrix[MissingQubits[i], :] = 0\n",
    "        AdjacencyMatrix[:, MissingQubits[i]] = 0\n",
    "\n",
    "    # Create a random mapping form variables to qubits used\n",
    "    QubitMapping = np.column_stack((np.arange(1,Nvariables+1), np.random.permutation(QubitsUsed)[:Nvariables]))\n",
    "\n",
    "    # Compute adjacency matrix of mapped variables\n",
    "    AdjMat = AdjacencyMatrix[QubitMapping[:,1]-1, QubitMapping[:,1]-1]\n",
    "\n",
    "    return QubitMapping, AdjMat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def StochasticGreedyEmbedding(J, AdjacencyMatrix, StartingQubit):\n",
    "    #GREEDYEMBEDDING Generates an embedding that prioritizes keeping the\n",
    "    #strongest connections of J.\n",
    "\n",
    "    # Inputs:\n",
    "    #\n",
    "    #  J  : Interaction matrix to be approximated\n",
    "    #  AdjacencyMatrix : Adjacency matrix of the chip\n",
    "    #  StartingQubit : Initial qubit to start the embedding (picking one with \n",
    "    #                  high connectivity and somwhere around the center of the\n",
    "    #                  chip recommended)\n",
    "    #\n",
    "    #\n",
    "    # Outputs: \n",
    "    #\n",
    "    #  QuibtMapping : N x 2 matrix, first column is a list of variables of\n",
    "    #  the quadratic function, second column has the qubits assigned to those\n",
    "    #  variables\n",
    "    #  AdjMat : reduced adjacency matrix representing the connections between\n",
    "    #  the qubits chosen from the embedding\n",
    "\n",
    "    J = J - np.diag(np.diag(J))\n",
    "\n",
    "    Nvars = J.shape[0]\n",
    "    Nqubits = 512  # Total number of qubits in Vesuvius (used for indexing)    \n",
    "    Qubit = StartingQubit\n",
    "\n",
    "    MissingQubits = np.where((np.sum(AdjacencyMatrix, axis=1)) == 0)[0] # Missing qubits in processor\n",
    "\n",
    "    #Remove Missing qubits from AdjacencyMatrix (in case they're still there)\n",
    "    for i in range(len(MissingQubits)):\n",
    "        AdjacencyMatrix[MissingQubits[i], :] = 0*AdjacencyMatrix[MissingQubits[i], :]\n",
    "        AdjacencyMatrix[:, MissingQubits[i]] = 0*AdjacencyMatrix[:, MissingQubits[i]]\n",
    "\n",
    "\n",
    "    [~, StrongCouplingIndex] = np.max(np.sum(np.abs(J), axis=1)) # Find the index with the strongest coupling\n",
    "\n",
    "    VariablesLeft = np.arange(1, Nvars+1)\n",
    "    VariablesAssigned = []\n",
    "\n",
    "    QubitsAssigned = []\n",
    "    QubitsLeft = np.arange(1, Nqubits+1)\n",
    "    QubitsLeft = np.delete(QubitsLeft, MissingQubits)\n",
    "\n",
    "    VariablesAssigned = [StrongCouplingIndex]\n",
    "    VariablesLeft = np.delete(VariablesLeft, StrongCouplingIndex-1) # Remove the assigned variable from list of variables\n",
    "    J[:, StrongCouplingIndex-1] = np.zeros((Nvars, 1))\n",
    "\n",
    "    QubitsAssigned = [QubitsAssigned, Qubit]\n",
    "\n",
    "    QubitNeighbors = np.where(AdjacencyMatrix[Qubit-1, :] != 0)[0] # Qubits adjacent to first assigned qubit\n",
    "\n",
    "    for n in range(2, Nvars+1):\n",
    "\n",
    "        for i in range(len(VariablesLeft)):\n",
    "            for j in range(len(QubitNeighbors)):\n",
    "                Coupling = 0\n",
    "                for k in range(len(VariablesAssigned)):\n",
    "                    Coupling = Coupling + np.abs(J[VariablesAssigned[\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def GenerateQubitsUsed(AdjacencyMatrix):\n",
    "    MissingQubits = np.where(np.sum(AdjacencyMatrix, axis=1) == 0)[0]\n",
    "\n",
    "    CellsPerSide = 8\n",
    "    QubitsPerCell = 8\n",
    "\n",
    "    CellOrder = np.array([[4, 4], [4, 5], [5, 5], [5, 4]])\n",
    "    ct = 4\n",
    "\n",
    "    for k in range(int(CellsPerSide/2 -1), 0, -1):\n",
    "        for j in range(np.min(CellOrder[:,1]), np.max(CellOrder[:,1])+1):\n",
    "            ct += 1\n",
    "            CellOrder = np.append(CellOrder, [[k, j]], axis=0)\n",
    "\n",
    "        for i in range(k+1, CellsPerSide-k+1):\n",
    "            ct += 1\n",
    "            CellOrder = np.append(CellOrder, [[i, CellOrder[ct-1,1]]], axis=0)\n",
    "\n",
    "        for j in range(CellOrder[ct,1]-1, np.min(CellOrder[:,1])-1, -1):\n",
    "            ct += 1\n",
    "            CellOrder = np.append(CellOrder, [[CellsPerSide-k+1, j]], axis=0)\n",
    "\n",
    "        for i in range(CellsPerSide-k, k, -1):\n",
    "            ct += 1\n",
    "            CellOrder = np.append(CellOrder, [[i, CellOrder[ct-1,1]]], axis=0)\n",
    "\n",
    "    HorizontalCell = [5, 1, 6, 2, 7, 3, 8, 4]\n",
    "    VerticalCell = [1, 5, 2, 6, 3, 7, 4, 8]\n",
    "\n",
    "    QubitsUsed = ((CellOrder[0,0]-1)*CellsPerSide*8+(CellOrder[0,1]-1)*QubitsPerCell)+VerticalCell\n",
    "\n",
    "    for k in range(1, CellOrder.shape[0]):\n",
    "\n",
    "        if CellOrder[k,1] != CellOrder[k,1]:\n",
    "            QubitsUsed = np.append(QubitsUsed, ((CellOrder[k,0]-1)*CellsPerSide*8+(CellOrder[k,1]-1)*QubitsPerCell)+HorizontalCell)\n",
    "        else:\n",
    "            QubitsUsed = np.append(QubitsUsed, ((CellOrder[k,0]-1)*CellsPerSide*8+(CellOrder[k,1]-1)*QubitsPerCell)+VerticalCell)\n",
    "\n",
    "    for i in range(MissingQubits.shape[0]):\n",
    "        index = np.where(QubitsUsed == MissingQubits[i])[0]\n",
    "        QubitsUsed = np.delete(QubitsUsed, index)\n",
    "\n",
    "    return QubitsUsed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvec\u001b[39m(X):\n\u001b[1;32m      4\u001b[0m     m, n \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "\n",
    "def vec(X):\n",
    "    m, n = X.shape\n",
    "    x = X.reshape(m*n, 1)\n",
    "    return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Oct 13 2022, 09:48:40) [Clang 14.0.0 (clang-1400.0.29.102)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
